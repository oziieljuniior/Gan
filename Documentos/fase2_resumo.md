# âœ… VisÃ£o Geral da Fase 2

A Fase 2 consiste em **treinar um GAN simples** (com uma camada escondida em cada rede), para que o **Generator aprenda a criar vetores RSSI realistas**, indistinguÃ­veis dos reais pelo Discriminator.

---

## ğŸ§  Estrutura do GAN

### ğŸ¯ Objetivo:

* **Entrada do Generator**: vetor de ruÃ­do $z \sim \mathcal{U}(-1, 1)^{10}$
* **SaÃ­da do Generator**: vetor de RSSI com 10 valores (simulando os 10 APs)
* **Discriminator**: tenta diferenciar vetores reais de vetores gerados
* **Treinamento adversarial**: Generator tenta enganar o Discriminator

---

## ğŸ—‚ï¸ Preciso de banco de dados?

### âŒ **VocÃª NÃƒO precisa carregar um banco externo agora.**

VocÃª **jÃ¡ possui os dados simulados reais**, que sÃ£o os **1000 vetores RSSI reais**, salvos em `df_simulated.csv`. Eles devem ser carregados (ou mantidos em memÃ³ria) no inÃ­cio da Etapa 2:

```python
# Se quiser recarregar do CSV (opcional)
df_simulated = pd.read_csv("data/df_simulated.csv")
X_real = df_simulated.iloc[:, :10].values.astype(np.float32)
```

---

## ğŸ”§ Etapas da ImplementaÃ§Ã£o â€“ Explicadas

### âœ… 1. **PrÃ©-processamento**

* Extraia os 10 primeiros campos de cada vetor (`WAP001` a `WAP010`)
* Normalize se necessÃ¡rio (nÃ£o essencial, pois valores jÃ¡ estÃ£o em faixa comum de dBm)

### âœ… 2. **Definir as arquiteturas**

* `Generator`: input=(10,), Dense(10 ReLU), Dense(10 linear)
* `Discriminator`: input=(10,), Dense(10 ReLU), Dense(1 sigmoid)

### âœ… 3. **Compilar os modelos**

* `Discriminator`: binÃ¡ria, `loss='binary_crossentropy'`, `Adam(0.01)`
* `GAN`: conecta G â†’ D, e compila com mesmo loss/otimizador

### âœ… 4. **Treinar por 200 Ã©pocas**

* Em cada Ã©poca:

  * Gerar amostras fake: `G(z)`
  * Misturar com amostras reais: `X_real`
  * Treinar o Discriminator separadamente com:

    * 50% reais (label=1), 50% fakes (label=0)
  * Depois congelar o Discriminator e treinar o Generator via GAN com `label=1` (engane o D)

### âœ… 5. **Salvar perdas (losses)**

* Guardar os valores `loss_d` e `loss_g` por Ã©poca para plotar depois

### âœ… 6. **Gerar vetores RSSI sintÃ©ticos**

* ApÃ³s treino, usar `generator.predict(z)` com `z.shape = (40000, 10)`
* Salvar `df_generated.csv` para as prÃ³ximas fases

---

## âš ï¸ Coisas para ficar atento

### ğŸ”¹ Overfitting do Discriminator:

* Se o Discriminator ficar muito bom, o Generator para de melhorar
* Use aprendizado balanceado (re-treine o D e o G alternadamente)

### ğŸ”¹ GeraÃ§Ã£o fora da faixa esperada:

* RSSI deve ficar entre \~\[-110, -40]
* Pode ser necessÃ¡rio aplicar `np.clip(v, -110, -40)` na saÃ­da do Generator

### ğŸ”¹ Perda instÃ¡vel (normal em GANs):

* FlutuaÃ§Ãµes de `loss_d` e `loss_g` sÃ£o esperadas, mas devem convergir levemente

---

## âœ… Resumo da Estrutura

```text
| Parte                    | Tarefa                                     |
|--------------------------|--------------------------------------------|
| Dados reais              | 1000 vetores do df_simulated (WAP001â€“010) |
| Generator                | Densa (10 ReLU) â†’ Densa (10 linear)       |
| Discriminator            | Densa (10 ReLU) â†’ Densa (1 sigmoid)       |
| Perda                    | BCE (binary cross-entropy)                |
| Otimizador               | Adam (lr=0.01)                             |
| Treinamento              | 200 Ã©pocas, alternando D e G              |
| SaÃ­da final              | 40000 vetores sintÃ©ticos (para fase 3)    |
```

---

